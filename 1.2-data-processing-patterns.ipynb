{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f7ba2e-4936-4f86-82dc-b8a78f6d6472",
   "metadata": {},
   "source": [
    "## Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bbcd3-ee1b-42cb-9071-75c4d0c672ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "https://medium.com/@farukdemirok/hybrid-recommender-system-811ee411b697 - proceesubf dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "beb729f3-edac-4c7a-aad5-649a276a9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ast\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfd16d-dc28-42c2-bfbc-bb4e754a951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # colsolidate into one dataframe\n",
    "# df = four_star.append(five_star_clothing, ignore_index=True)\n",
    "# df = df.append(five_star_not_clothing, ignore_index=True)\n",
    "# df.shape\n",
    "\n",
    "# # remove any rows with headers\n",
    "# df = df.drop(df[df['pattern_id']=='pattern_id'].index)\n",
    "# # drop douplicates\n",
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f76253ef-0013-4303-b37c-5b2aa49cf3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/consolidated_patterns.csv', low_memory=False)\n",
    "\n",
    "def clean_out_bad_data(df):\n",
    "    # extra indicies from .csv appending and accidental douplicates\n",
    "    df = df.drop(df[df['pattern_id']=='pattern_id'].index)\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # not enough projects (43451 rows)\n",
    "    df = df.drop(df[df['projects_count'] <= 10].index)\n",
    "    \n",
    "    # drop rows with too many nulls (15795 rows)\n",
    "    df = df.drop(df[df.isnull().sum(axis=1) >3].index)\n",
    "    \n",
    "    # drop if no category\n",
    "    df = df.drop(df[df['categories'].isna()].index)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Need to save and reload clean data!! \n",
    "df = clean_out_bad_data(df)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.to_csv('data/patterns_cleaned.csv', index=False)\n",
    "\n",
    "# # INCLUDE WEIGHTED AVERAGE SCORE RATHER THAN RATING?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8dda604-0145-4d80-b954-dfee50564182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pattern_id', 'name', 'name_permalink', 'favorites_count',\n",
       "       'projects_count', 'difficulty_average', 'difficulty_count',\n",
       "       'rating_average', 'queued_projects_count', 'rating_count',\n",
       "       'pattern_type_names', 'pattern_type_clothing', 'photos_url',\n",
       "       'pattern_needle_sizes', 'pattern_attributes', 'yardage_max', 'yardage',\n",
       "       'generally_available', 'gauge', 'gauge_divisor', 'free', 'downloadable',\n",
       "       'categories', 'yarn_weight_description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b807a-5f03-4cb6-b390-d0dad52bd345",
   "metadata": {},
   "source": [
    "#### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25409e81-a036-4d70-80f5-5da3051e0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_columns = ['pattern_type_clothing','downloadable',\n",
    "#                'free','categories', 'pattern_type_names','pattern_attributes','yarn_weight_description']\n",
    "# # THERE IS A PATTERN TYPE ID _ JUST USE THAT?? instead of names??\n",
    "# # MAYBE REGROUP AND ONE HOT ENCODE? OR READJUST AND LABEL ENCODE IDS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c0ebd6-1428-4eae-bf0b-7940330c2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.isnull().sum(axis=1) >3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4017dd88-d9ed-4038-b3d3-3cf2b2347326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  7 17  2  3  1  9  6  8 20 16  4 19 15  5 11 21 13 18]\n",
      "['shawl' 'cardigan' 'child' 'socks' 'hat' 'scarf' 'other' 'pet' 'gloves'\n",
      " 'shrug' 'toys' 'pullover' 'jacket' 'bag' 'baby' 'blanket' 'home' 'vest'\n",
      " 'tee']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # PATTERN_TYPES (ID AND NAMES)\n",
    "# print(pat.pattern_type_id.unique())\n",
    "# print(pat['pattern_type_names'].unique())\n",
    "# len(pat.pattern_type_names.unique())\n",
    "# # one hot encode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d23598d5-8624-4289-80b2-6ec1bbbfebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528ba01f-93d4-4771-9e1a-fe19697a354f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e41c85da-74b5-4480-bd2a-de145bac395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 132843 entries, 0 to 188156\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   pattern_id               132843 non-null  int64  \n",
      " 1   name                     132843 non-null  object \n",
      " 2   name_permalink           132843 non-null  object \n",
      " 3   favorites_count          132843 non-null  int64  \n",
      " 4   projects_count           132843 non-null  int64  \n",
      " 5   difficulty_average       132843 non-null  float64\n",
      " 6   difficulty_count         131547 non-null  float64\n",
      " 7   rating_average           132843 non-null  float64\n",
      " 8   queued_projects_count    132843 non-null  int64  \n",
      " 9   rating_count             132841 non-null  float64\n",
      " 10  pattern_type_names       132842 non-null  object \n",
      " 11  pattern_type_clothing    132842 non-null  object \n",
      " 12  photos_url               132843 non-null  object \n",
      " 13  pattern_needle_sizes     132843 non-null  object \n",
      " 14  pattern_attributes       132843 non-null  object \n",
      " 15  yardage_max              90456 non-null   float64\n",
      " 16  yardage                  114363 non-null  float64\n",
      " 17  generally_available      132843 non-null  object \n",
      " 18  gauge                    119547 non-null  float64\n",
      " 19  gauge_divisor            125876 non-null  float64\n",
      " 20  free                     132840 non-null  object \n",
      " 21  downloadable             132841 non-null  object \n",
      " 22  categories               132843 non-null  object \n",
      " 23  yarn_weight_description  130665 non-null  object \n",
      "dtypes: float64(8), int64(4), object(12)\n",
      "memory usage: 25.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "# find percentage null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8e7d4b0-786e-4cdf-b924-d27a77830a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to one_hot encode, or true, false?\n",
    "# There are 19 pattern_type_names - not sure which one to use...\n",
    "cols_to_one_hot = ['pattern_type_clothing','downloadable','free','pattern_type_names'] # note pattern_type_names 19\n",
    "cols_to_count_vectorize = ['categories', 'pattern_attributes']\n",
    "cols_to_transform = ['yarn_weight_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413af4e3-3751-4be1-8678-8791b2ee8588",
   "metadata": {},
   "source": [
    "#### categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f11de0d6-e8d5-4022-a469-93d75a3322fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categories']\n",
    "def parse_out_single_category(df):\n",
    "    df['categories'] = df['categories'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['categories'] = df['categories'].apply(lambda x: x[0])\n",
    "    return df\n",
    "df_categories = parse_out_single_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdd2bdb5-51d0-4aa3-ae06-63cb22293cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories.categories\n",
    "df_categories_dummies = pd.Series(df_categories['categories']).str.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b074e5f4-3cb7-4d36-a804-8bc2256b9730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132843, 189)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4f746-ec73-4425-b23b-37d90d121d69",
   "metadata": {},
   "source": [
    "#### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44c20b-3564-4f87-ae2d-f64e55eecbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8636fd-a72a-4f21-8651-c1e3c9436704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "869b8d32-83e7-49bf-9d28-fee5bf3d659e",
   "metadata": {},
   "source": [
    "### Functions for DataFrame Function Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c5aa9f0-6043-46a6-a78f-ebac40528aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_identifying_columns(df):\n",
    "    df.drop(columns = ['pattern_id','name', \n",
    "                        'name_permalink','photos_url', 'pattern_attributes', \n",
    "                       'pattern_type_names','categories','rating_count','favorites_count', \n",
    "                       'projects_count','rating_average',\n",
    "                       'difficulty_count','queued_projects_count'], inplace= True)\n",
    "    return df\n",
    "#----------------------------------pattern attributes actually need to be vectorized\n",
    "def consolidate_gauge(df):\n",
    "    \"\"\" takes in gauge columns and normalizes them all to stiches per inch \"\"\"\n",
    "    try:\n",
    "        df['gauge_per_inch'] = df.loc[:,'gauge']/df.loc[:,'gauge_divisor']\n",
    "        df.drop(columns = ['gauge', 'gauge_divisor'], axis = 1, inplace = True)\n",
    "    except:\n",
    "        print(\"Error occured when consolidating gauge\")\n",
    "    return df\n",
    "\n",
    "def encode_yarn_weights(df):\n",
    "    \"\"\" uses yarn_weight_description to convert weights correspnding actual relative thicknesses\n",
    "    indstry standards splits into 7 categories, but this goes more ganually \"\"\"\n",
    "    yarn_weights = {'Lace' : 1,\n",
    "                    'Thread':1,\n",
    "                    'Cobweb':1,\n",
    "                    'Light Fingering':1.5,\n",
    "                    'Fingering (14 wpi)': 2,\n",
    "                    'Sport (12 wpi)': 3,\n",
    "                    'DK / Sport' : 4,\n",
    "                    'DK (11 wpi)' : 5,\n",
    "                    'Worsted (9 wpi)':6,\n",
    "                    'Aran / Worsted': 7,\n",
    "                    'Aran (8 wpi)': 8,\n",
    "                    'Bulky (7 wpi)':9,\n",
    "                    'Super Bulky (5-6 wpi)':10,\n",
    "                    'Jumbo (0-4 wpi)':11,\n",
    "                    'No weight specified':5,\n",
    "                    'Any gauge - designed for any gauge':5}\n",
    "    ##--------------need to get yarn weight for other \n",
    "    try:\n",
    "        df.replace({'yarn_weight_description':yarn_weights}, inplace=True)\n",
    "        df.rename(columns = {'yarn_weight_description':'yarn_weight_code'}, inplace=True)\n",
    "    except:\n",
    "        print(\"okay - check out yarn_weight_description, something went wrong with the encoding\")\n",
    "    return df\n",
    "\n",
    "# # NOT USED - using average for now\n",
    "# def fill_max_yardage(df):\n",
    "#     \"\"\" if there the yardage column is filled, but max_yardage is empty, it's because there isn't a \n",
    "#     range of yardage (in the case of one-sized non-clothing items).  This function fills that column in the c\n",
    "#     case we only want to use min or max yardage \"\"\"\n",
    "#     df['yardage_max'] = df['yardage_max'].fillna(df['yardage'])\n",
    "#     return df\n",
    "\n",
    "def use_avg_yardage(df):\n",
    "    df['yardage_max'] = df['yardage_max'].fillna(df['yardage'])\n",
    "    df['yardage_avg'] = (df['yardage'] + df['yardage_max'])/2\n",
    "    df.drop(columns=['yardage_max','yardage'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def split_date_released(df):\n",
    "    \"\"\" takes in 'generally_available' column and splits out into month and year \n",
    "    (to take into account seasonal purchases, and yearly impacts)\"\"\"\n",
    "    try:\n",
    "        df['generally_available'] = pd.to_datetime(df['generally_available'], utc=True)\n",
    "        df['month_avail'] = df.generally_available.dt.month\n",
    "        df['year_avail'] = df.generally_available.dt.year\n",
    "     \n",
    "        df.drop(columns = ['generally_available'], axis = 1, inplace = True)\n",
    "    except:\n",
    "        \"print - Error occured when trying to split dates\"\n",
    "    return df\n",
    "\n",
    "def get_list_metric_needles(x):\n",
    "    \"\"\"Get the list of metric needle sizes for knitting (can have several needle sizes for various parts of the pattern \n",
    "    and crochet hooks for finishing.  Generally the largest needle is the \n",
    "    one used for the main body (or largest portion of the project) \"\"\"\n",
    "    n=[]\n",
    "    for i in range(len(x)):\n",
    "        if x[i]['knitting'] == True:\n",
    "            n.append(x[i]['metric'])\n",
    "    return n\n",
    "\n",
    "def get_needle_size(df):\n",
    "    try:\n",
    "        df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: ast.literal_eval(x))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df['pattern_needle_sizes'] = df['pattern_needle_sizes'].apply(lambda x: get_list_metric_needles(x))\n",
    "    df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: max(x) if (len(x)>=1) else None)\n",
    "    return df\n",
    "\n",
    "# def calculate_popularity(df):\n",
    "#     pass\n",
    "# # get_weighted_rating\n",
    "\n",
    "def parse_out_single_category(df):\n",
    "    df['categories'] = df['categories'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['categories'] = df['categories'].apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def vectorize_categories(df):\n",
    "    pass\n",
    "# count_vect = CountVectorizer()\n",
    "\n",
    "def vectorize_pattern_attributes(df):\n",
    "    corpus = df['attributes'].tolist()\n",
    "    \n",
    "def impute_missing_values_or_zeros(df):\n",
    "    df['difficulty_average'].fillna(df['difficulty_average'].median(), inplace=True)\n",
    "    df['pattern_type_clothing'].fillna(df['pattern_type_clothing'].median(), inplace=True)\n",
    "    df['pattern_needle_sizes'].fillna(df['pattern_needle_sizes'].median(), inplace=True)\n",
    "    df['free'].fillna(df['free'].median(), inplace=True)\n",
    "    df['downloadable'].fillna(df['downloadable'].median(), inplace=True)\n",
    "    df['yarn_weight_code'].fillna(df['yarn_weight_code'].median(), inplace=True)\n",
    "    df['gauge_per_inch'].fillna(df['gauge_per_inch'].median(), inplace=True)\n",
    "#        'month_avail', 'year_avail', \n",
    "    df['yardage_avg'].fillna(df['yardage_avg'].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# def one_hot_encode_binary(df):\n",
    "    \n",
    "#     feature_to_encode = ['pattern_type_clothing','free','downloadable'] \n",
    "#     dummies = pd.get_dummies(df[[feature_to_encode]], drop_first=True)\n",
    "#     res = pd.concat([df, dummies], axis=1)\n",
    "#     res = res.drop([feature_to_encode], axis=1)\n",
    "#     return(res)\n",
    "\n",
    "def apply_weighting_values(df):\n",
    "    pass\n",
    "\n",
    "#     using count isnt meaningful here ----------\n",
    "# def get_weighted_difficulty_average(df):\n",
    "#     overal_difficulty_average = df.difficulty_average.mean()\n",
    "\n",
    "# def convert_to_sentence(x):\n",
    "#     # concatenate words with '-'\n",
    "    \n",
    "#     # covert from list to sentence\n",
    "#     x = ' '.join(word for word in x)\n",
    "#     x = x.replace('-','')\n",
    "#     #consolidatae and remove a number of words! right now 245-----------------------------\n",
    "#     return x\n",
    "\n",
    "# df['pattern_attributes'] = df['pattern_attributes'].apply(lambda x: ast.literal_eval(x))\n",
    "# df['pattern_attributes'] = df['pattern_attributes'].apply(lambda x: convert_to_sentence(x))\n",
    "# corpus = df['pattern_attributes']\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "# features = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# This one works lovely \n",
    "def transform_features(data):\n",
    "    data['yardage_avg'] = use_avg_yardage(df)\n",
    "    encode_yarn_weights(df)\n",
    "    data['Total_Income_Log'] = np.log(data['ApplicantIncome'] + data['CoapplicantIncome'])\n",
    "    data['LoanAmt_Term_Ratio_Log']=  np.log(data['LoanAmount']/data['Loan_Amount_Term'])\n",
    "    data['LoanAmount_Log'] = np.log(data['LoanAmount'])\n",
    "    data.drop(labels=['ApplicantIncome','CoapplicantIncome', 'LoanAmount'], axis=1, inplace=True)\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n",
    "\n",
    "# add_total_income_log_object = FunctionTransformer(replace_income_with_total_income_log)\n",
    "# add_loanamt_term_ratio_log_object = FunctionTransformer(add_LoanAmt_Term_Ratio_Log)\n",
    "# add_loanamount_log_object = FunctionTransformer(replace_loanamount_with_loanamount_log)\n",
    "\n",
    "transform_features = FunctionTransformer(transform_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c9956-a58e-484a-9d29-e251779de8e3",
   "metadata": {},
   "source": [
    "Try one ginormous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9be71-f3ec-4685-8581-d75dd084fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_identifying_columns(df):\n",
    "    df.drop(columns = ['pattern_id','name', \n",
    "                        'name_permalink','photos_url', 'pattern_attributes', \n",
    "                       'pattern_type_names','categories','rating_count','favorites_count', \n",
    "                       'projects_count','rating_average',\n",
    "                       'difficulty_count','queued_projects_count'], inplace= True)\n",
    "    return df\n",
    "#----------------------------------pattern attributes actually need to be vectorized\n",
    "def consolidate_gauge(df):\n",
    "    \"\"\" takes in gauge columns and normalizes them all to stiches per inch \"\"\"\n",
    "    try:\n",
    "        df['gauge_per_inch'] = df.loc[:,'gauge']/df.loc[:,'gauge_divisor']\n",
    "        df.drop(columns = ['gauge', 'gauge_divisor'], axis = 1, inplace = True)\n",
    "    except:\n",
    "        print(\"Error occured when consolidating gauge\")\n",
    "    return df\n",
    "\n",
    "def encode_yarn_weights(df):\n",
    "    \"\"\" uses yarn_weight_description to convert weights correspnding actual relative thicknesses\n",
    "    indstry standards splits into 7 categories, but this goes more ganually \"\"\"\n",
    "    yarn_weights = {'Lace' : 1,\n",
    "                    'Thread':1,\n",
    "                    'Cobweb':1,\n",
    "                    'Light Fingering':1.5,\n",
    "                    'Fingering (14 wpi)': 2,\n",
    "                    'Sport (12 wpi)': 3,\n",
    "                    'DK / Sport' : 4,\n",
    "                    'DK (11 wpi)' : 5,\n",
    "                    'Worsted (9 wpi)':6,\n",
    "                    'Aran / Worsted': 7,\n",
    "                    'Aran (8 wpi)': 8,\n",
    "                    'Bulky (7 wpi)':9,\n",
    "                    'Super Bulky (5-6 wpi)':10,\n",
    "                    'Jumbo (0-4 wpi)':11,\n",
    "                    'No weight specified':5,\n",
    "                    'Any gauge - designed for any gauge':5}\n",
    "    ##--------------need to get yarn weight for other \n",
    "    try:\n",
    "        df.replace({'yarn_weight_description':yarn_weights}, inplace=True)\n",
    "        df.rename(columns = {'yarn_weight_description':'yarn_weight_code'}, inplace=True)\n",
    "    except:\n",
    "        print(\"okay - check out yarn_weight_description, something went wrong with the encoding\")\n",
    "    return df\n",
    "\n",
    "# # NOT USED - using average for now\n",
    "# def fill_max_yardage(df):\n",
    "#     \"\"\" if there the yardage column is filled, but max_yardage is empty, it's because there isn't a \n",
    "#     range of yardage (in the case of one-sized non-clothing items).  This function fills that column in the c\n",
    "#     case we only want to use min or max yardage \"\"\"\n",
    "#     df['yardage_max'] = df['yardage_max'].fillna(df['yardage'])\n",
    "#     return df\n",
    "\n",
    "def use_avg_yardage(df):\n",
    "    df['yardage_max'] = df['yardage_max'].fillna(df['yardage'])\n",
    "    df['yardage_avg'] = (df['yardage'] + df['yardage_max'])/2\n",
    "    df.drop(columns=['yardage_max','yardage'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def split_date_released(df):\n",
    "    \"\"\" takes in 'generally_available' column and splits out into month and year \n",
    "    (to take into account seasonal purchases, and yearly impacts)\"\"\"\n",
    "    try:\n",
    "        df['generally_available'] = pd.to_datetime(df['generally_available'], utc=True)\n",
    "        df['month_avail'] = df.generally_available.dt.month\n",
    "        df['year_avail'] = df.generally_available.dt.year\n",
    "     \n",
    "        df.drop(columns = ['generally_available'], axis = 1, inplace = True)\n",
    "    except:\n",
    "        \"print - Error occured when trying to split dates\"\n",
    "    return df\n",
    "\n",
    "def get_list_metric_needles(x):\n",
    "    \"\"\"Get the list of metric needle sizes for knitting (can have several needle sizes for various parts of the pattern \n",
    "    and crochet hooks for finishing.  Generally the largest needle is the \n",
    "    one used for the main body (or largest portion of the project) \"\"\"\n",
    "    n=[]\n",
    "    for i in range(len(x)):\n",
    "        if x[i]['knitting'] == True:\n",
    "            n.append(x[i]['metric'])\n",
    "    return n\n",
    "\n",
    "def get_needle_size(df):\n",
    "    try:\n",
    "        df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: ast.literal_eval(x))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df['pattern_needle_sizes'] = df['pattern_needle_sizes'].apply(lambda x: get_list_metric_needles(x))\n",
    "    df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: max(x) if (len(x)>=1) else None)\n",
    "    return df\n",
    "\n",
    "# def calculate_popularity(df):\n",
    "#     pass\n",
    "# # get_weighted_rating\n",
    "\n",
    "def parse_out_single_category(df):\n",
    "    df['categories'] = df['categories'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['categories'] = df['categories'].apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def vectorize_categories(df):\n",
    "    pass\n",
    "# count_vect = CountVectorizer()\n",
    "\n",
    "def vectorize_pattern_attributes(df):\n",
    "    corpus = df['attributes'].tolist()\n",
    "    \n",
    "def impute_missing_values_or_zeros(df):\n",
    "    df['difficulty_average'].fillna(df['difficulty_average'].median(), inplace=True)\n",
    "    df['pattern_type_clothing'].fillna(df['pattern_type_clothing'].median(), inplace=True)\n",
    "    df['pattern_needle_sizes'].fillna(df['pattern_needle_sizes'].median(), inplace=True)\n",
    "    df['free'].fillna(df['free'].median(), inplace=True)\n",
    "    df['downloadable'].fillna(df['downloadable'].median(), inplace=True)\n",
    "    df['yarn_weight_code'].fillna(df['yarn_weight_code'].median(), inplace=True)\n",
    "    df['gauge_per_inch'].fillna(df['gauge_per_inch'].median(), inplace=True)\n",
    "#        'month_avail', 'year_avail', \n",
    "    df['yardage_avg'].fillna(df['yardage_avg'].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# def one_hot_encode_binary(df):\n",
    "    \n",
    "#     feature_to_encode = ['pattern_type_clothing','free','downloadable'] \n",
    "#     dummies = pd.get_dummies(df[[feature_to_encode]], drop_first=True)\n",
    "#     res = pd.concat([df, dummies], axis=1)\n",
    "#     res = res.drop([feature_to_encode], axis=1)\n",
    "#     return(res)\n",
    "\n",
    "def apply_weighting_values(df):\n",
    "    pass\n",
    "\n",
    "#     using count isnt meaningful here ----------\n",
    "# def get_weighted_difficulty_average(df):\n",
    "#     overal_difficulty_average = df.difficulty_average.mean()\n",
    "\n",
    "# def convert_to_sentence(x):\n",
    "#     # concatenate words with '-'\n",
    "    \n",
    "#     # covert from list to sentence\n",
    "#     x = ' '.join(word for word in x)\n",
    "#     x = x.replace('-','')\n",
    "#     #consolidatae and remove a number of words! right now 245-----------------------------\n",
    "#     return x\n",
    "\n",
    "# df['pattern_attributes'] = df['pattern_attributes'].apply(lambda x: ast.literal_eval(x))\n",
    "# df['pattern_attributes'] = df['pattern_attributes'].apply(lambda x: convert_to_sentence(x))\n",
    "# corpus = df['pattern_attributes']\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "# features = vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# # This one works lovely \n",
    "# def transform_features(data):\n",
    "#     data['yardage_avg'] = use_avg_yardage(df)\n",
    "#     encode_yarn_weights(df)\n",
    "#     data['Total_Income_Log'] = np.log(data['ApplicantIncome'] + data['CoapplicantIncome'])\n",
    "#     data['LoanAmt_Term_Ratio_Log']=  np.log(data['LoanAmount']/data['Loan_Amount_Term'])\n",
    "#     data['LoanAmount_Log'] = np.log(data['LoanAmount'])\n",
    "#     data.drop(labels=['ApplicantIncome','CoapplicantIncome', 'LoanAmount'], axis=1, inplace=True)\n",
    "#     data.reset_index(inplace=True)\n",
    "#     return data\n",
    "\n",
    "# add_total_income_log_object = FunctionTransformer(replace_income_with_total_income_log)\n",
    "# add_loanamt_term_ratio_log_object = FunctionTransformer(add_LoanAmt_Term_Ratio_Log)\n",
    "# add_loanamount_log_object = FunctionTransformer(replace_loanamount_with_loanamount_log)\n",
    "\n",
    "transform_features = FunctionTransformer(transform_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef5ea2a7-1772-4d2a-9a90-de9483db15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/consolidated_patterns.csv', low_memory=False)\n",
    "df = clean_out_bad_data(df)\n",
    "\n",
    "# features  #245 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072dcb10-329d-438d-b489-3cd859f3ca22",
   "metadata": {},
   "source": [
    "### Column Transform try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c140f3c8-a143-429f-95a9-afafee3298d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(\n",
    "     [('one_hot_encode', OneHotEncoder(dtype='int'), ['pattern_type_clothing','downloadable','free','pattern_type_names', 'categories']),\n",
    "#       ('attributes_bow', CountVectorizer(), ['attributes'])],\n",
    "     ],remainder='passthrough')\n",
    "\n",
    "# >>> column_trans.fit(X)\n",
    "# ColumnTransformer(transformers=[('categories', OneHotEncoder(dtype='int'),\n",
    "#                                  ['city']),\n",
    "#                                 ('title_bow', CountVectorizer(), 'title')],\n",
    "#                   verbose_feature_names_out=False)\n",
    "\n",
    "# >>> column_trans.get_feature_names_out()\n",
    "# array(['city_London', 'city_Paris', 'city_Sallisaw', 'bow', 'feast',\n",
    "# 'grapes', 'his', 'how', 'last', 'learned', 'moveable', 'of', 'the',\n",
    "#  'trick', 'watson', 'wrath'], ...)\n",
    "\n",
    "# >>> column_trans.transform(X).toarray()\n",
    "# array([[1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "#        [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "#        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "#        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1]]...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e292c5fa-6282-4cbe-889f-6daf0b0463ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_trans.fit(df)\n",
    "# column_trans.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406df15e-d770-40f8-95b9-96d066ed6ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f597e-4706-4991-acfe-72595d089cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a8b5970-67be-4ad2-b591-cf2d0bccc182",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4940a3a1-a5f2-449d-9473-bb6996e1a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeFunctionTransformer():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "# transformer_step = ColumnTransformer([\n",
    "#         ('impute_mean', SimpleImputer(strategy='mean'), ['age'])\n",
    "#     ], remainder='passthrough')\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('select', transformer_step)\n",
    "# ])\n",
    "    \n",
    "# ('one-hot-encode', OneHotEncoder(sparse=False))\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "imp = SimpleImputer()\n",
    "imp_constant = SimpleImputer(strategy='constant')\n",
    "imp_median = SimpleImputer(strategy='median', add_indicator=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# column_transfomer = ColumnTransformer(\n",
    "#     [('encoder', ohe, ['pattern_type_clothing','free','downloadable']),],\n",
    "# # #     [('encoder', ohe, ['pattern_type_clothing','free','downloadable','pattern_type_names','categories']),\n",
    "# #      ('imputer', imp, ['pattern_type_clothing','free','downloadable'])],\n",
    "#     remainder='passthrough') #any columns not named, pass through\n",
    "\n",
    "# categorical_preprocessing = Pipeline([('ohe', OneHotEncoder(sparse=False))])\n",
    "# numerical_preprocessing = Pipeline([('imputation', SimpleImputer())])\n",
    "\n",
    "\n",
    "preprocesing_pipeline = Pipeline([\n",
    "#     (\"parse_out_single_category\", DataframeFunctionTransformer(parse_out_single_category)),\n",
    "    (\"drop_identifying_columns\", DataframeFunctionTransformer(drop_identifying_columns)), # remove pattern_type names and catefries after \n",
    "    (\"cosolidate_gauge\", DataframeFunctionTransformer(consolidate_gauge)),\n",
    "    (\"encode_yarn_weights\", DataframeFunctionTransformer(encode_yarn_weights)),\n",
    "    (\"get_needle_size\", DataframeFunctionTransformer(get_needle_size)), \n",
    "    (\"split_date_released\", DataframeFunctionTransformer(split_date_released)),\n",
    "    (\"use_avg_yardage\", DataframeFunctionTransformer(use_avg_yardage)),\n",
    "    (\"impute_missing_values_or_zeros\", DataframeFunctionTransformer(impute_missing_values_or_zeros)),\n",
    "#     (\"one_hot_encode_binary\", DataframeFunctionTransformer(one_hot_encode_binary)),\n",
    "#     (\"apply_weighting_values\", DataframeFunctionTransformer(apply_weighting_values)),\n",
    "    (\"one_hot_encode_and_impute_missing\", column_transfomer),\n",
    "#     (\"standard_scale\", scaler),\n",
    "   \n",
    "    \n",
    "])\n",
    "\n",
    "# categories - pick off top 3 and weighted onehot encode\n",
    "# one hot encode ['pattern_type_clothing','free','downloadable']\n",
    "# attributs - weighted count vecorize\n",
    "\n",
    "# scale\n",
    "\n",
    "# convert year down to 20 off and if before 2000 make 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9cba88c6-b0e7-4a79-91e4-4410774af881",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = preprocesing_pipeline.fit(df)\n",
    "\n",
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37500f9b-cee9-4be7-8f62-a135ae849a7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-99bffee18a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "features.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cff3a12f-3ab2-4e3d-ae6c-a45927e3cd38",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['pattern_id' 'name' 'name_permalink' 'photos_url' 'pattern_attributes'\\n 'pattern_type_names' 'categories' 'rating_count' 'favorites_count'\\n 'projects_count' 'rating_average' 'difficulty_count'\\n 'queued_projects_count'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-a8cbd229f291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthe_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocesing_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/test_env/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-ad0d477ed1de>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input_df, **transform_params)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtransform_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-d60d3bdcc1c7>\u001b[0m in \u001b[0;36mdrop_identifying_columns\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0;34m'pattern_type_names'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rating_count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'favorites_count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0;34m'projects_count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rating_average'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                        'difficulty_count','queued_projects_count'], inplace= True)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#----------------------------------pattern attributes actually need to be vectorized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/test_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/test_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/test_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/test_env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['pattern_id' 'name' 'name_permalink' 'photos_url' 'pattern_attributes'\\n 'pattern_type_names' 'categories' 'rating_count' 'favorites_count'\\n 'projects_count' 'rating_average' 'difficulty_count'\\n 'queued_projects_count'] not found in axis\""
     ]
    }
   ],
   "source": [
    "the_features = preprocesing_pipeline.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ce3281a-cd88-4602-9d97-6d1cadbeed40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'the_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-f92e4e4c7305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtransformed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'the_features' is not defined"
     ]
    }
   ],
   "source": [
    "transformed_df = pd.DataFrame(the_features, columns=features.get_feature_names())\n",
    "transformed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7304f8d0-5019-43fa-b7b1-371cbb2d5230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.816424</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.435581</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.851249</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.865684</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.853333</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>3052.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132843 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5         6     7    8     9     10      11  \\\n",
       "0       0.0  1.0  0.0  1.0  0.0  1.0  1.816424  5.00  8.0  5.00  12.0  2006.0   \n",
       "1       0.0  1.0  0.0  1.0  0.0  1.0  2.435581  2.50  2.0  8.00   4.0  2006.0   \n",
       "2       0.0  1.0  1.0  0.0  0.0  1.0  2.851249  4.00  3.0  5.00   5.0  2007.0   \n",
       "3       0.0  1.0  0.0  1.0  0.0  1.0  1.865684  3.50  5.0  5.50   3.0  2006.0   \n",
       "4       0.0  1.0  1.0  0.0  1.0  0.0  2.853333  2.50  2.0  7.50  10.0  2007.0   \n",
       "...     ...  ...  ...  ...  ...  ...       ...   ...  ...   ...   ...     ...   \n",
       "132838  1.0  0.0  0.0  1.0  0.0  1.0  1.571429  4.50  6.0  5.00   4.0  2013.0   \n",
       "132839  0.0  1.0  1.0  0.0  1.0  0.0  1.666667  3.75  2.0  4.00  12.0  2020.0   \n",
       "132840  0.0  1.0  0.0  1.0  0.0  1.0  1.200000  5.00  6.0  5.50  12.0  2020.0   \n",
       "132841  0.0  1.0  0.0  1.0  0.0  1.0  3.000000  4.50  3.0  5.25   1.0  2021.0   \n",
       "132842  0.0  1.0  1.0  0.0  0.0  1.0  1.333333  3.50  2.0  5.50   9.0  2021.0   \n",
       "\n",
       "            12  \n",
       "0         93.0  \n",
       "1        370.0  \n",
       "2        437.0  \n",
       "3        234.0  \n",
       "4        460.0  \n",
       "...        ...  \n",
       "132838   110.0  \n",
       "132839   960.0  \n",
       "132840   836.0  \n",
       "132841  1730.0  \n",
       "132842  3052.0  \n",
       "\n",
       "[132843 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(X)\n",
    "df1\n",
    "\n",
    "# NEED SCALING!!\n",
    "# NEED NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4e4c1db-e44f-4df6-ba74-4cea37cf42d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-9b413faf226f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mget_needle_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-9b413faf226f>\u001b[0m in \u001b[0;36mget_needle_size\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pattern_needle_sizes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pattern_needle_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_list_metric_needles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pattern_needle_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pattern_needle_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# def get_needle_size(df):\n",
    "#     try:\n",
    "#         df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: ast.literal_eval(x))\n",
    "#     except:\n",
    "#         pass\n",
    "#     df['pattern_needle_sizes'] = df['pattern_needle_sizes'].apply(lambda x: get_list_metric_needles(x))\n",
    "#     df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: max(x) if (len(x)>=1) else None)\n",
    "#     return df\n",
    "\n",
    "# get_needle_size(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b796828-4741-4873-9c3f-18a74a09aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['pattern_needle_sizes'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe5ab501-5aab-4ec2-973e-8ae4e1ae243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1f24990-65b6-4852-b894-076aae397b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "545f1f58-8735-4b58-a264-547602b9b94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pattern_needle_sizes'][0][0]['knitting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbe646e4-c0fc-4cc8-b53c-c662f0296506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         1.0\n",
       "3         0.0\n",
       "4         1.0\n",
       "         ... \n",
       "132838    0.0\n",
       "132839    1.0\n",
       "132840    0.0\n",
       "132841    0.0\n",
       "132842    1.0\n",
       "Name: 2, Length: 132843, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8321590b-99ef-4d6e-a6e0-991941ec9a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132843, 13)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89b8fb07-ebd2-4064-afeb-ef0a615cc212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "# From lecture\n",
    "pattern_to_use = X[2].reshape(1,-1)\n",
    "pattern_to_use\n",
    "# pattern_to_use = preprocesing_pipeline.transform(pattern_to_use)\n",
    "\n",
    "# # Find distances to other patterns\n",
    "distances = euclidean_distances(X, pattern_to_use)\n",
    "distances = distances.reshape(1,-1) \n",
    "\n",
    "# # Find the 3 indices with the minimum distance (highest similarity) to the car we're looking at\n",
    "ordered_indices = distances.argsort()\n",
    "closest_indices = ordered_indices[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66e63ed8-1bbd-4f5d-a6ab-d870dbda6c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     2,  73807,  27169, ...,  38168, 130250,  12837]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3ebd5-c4c4-4287-8659-c42bdfc997ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needle_size(df):\n",
    "    try:\n",
    "        df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: ast.literal_eval(x))\n",
    "    except:\n",
    "        pass\n",
    "    sizes =[]\n",
    "    for i in range(len(df['pattern_needle_sizes']):\n",
    "        if df['pattern_needle_sizes'][i][0]['knitting']=='True':\n",
    "            sizes.append(df['pattern_needle_sizes'][i][0]['metric']\n",
    "        else\n",
    "            sizes.append('None')\n",
    "                   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "553e00c2-da6f-4ec5-a94a-2d35f1a23379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c4175d-4ad4-45f9-bd6d-8fab47ed74f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b6fc276864e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pattern_needle_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print(df['pattern_needle_sizes'][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'knitting'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'True'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pattern_needle_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df['pattern_needle_sizes']= df['pattern_needle_sizes'].apply(lambda x: ast.literal_eval(x))\n",
    "except:\n",
    "    pass\n",
    "sizes =[]\n",
    "for i in df['pattern_needle_sizes']:\n",
    "#     print(df['pattern_needle_sizes'][i])\n",
    "    if i[0]['knitting']=='True':\n",
    "\n",
    "        sizes.append(df['pattern_needle_sizes'][i][0]['metric'])\n",
    "    else:\n",
    "        sizes.append('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e13e58-397e-40bc-abc7-9eb2df51f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Distance from all other cars\n",
    "# distances = euclidean_distances(X, looking_at_car)\n",
    "# distances = distances.reshape(-1)   # Before it was (n_cars, 1)\n",
    "\n",
    "# # Find the 3 indices with the minimum distance (highest similarity) to the car we're looking at\n",
    "# ordered_indices = distances.argsort()\n",
    "# closest_indices = ordered_indices[:3]\n",
    "\n",
    "# # Get the cars for these indices\n",
    "# closest_cars = cars.iloc[closest_indices]\n",
    "# closest_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "253a9896-eaef-4db3-95c8-87a3c5eed05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pattern_id                                                                88\n",
       "name                                                             Calorimetry\n",
       "name_permalink                                                   calorimetry\n",
       "favorites_count                                                        29838\n",
       "projects_count                                                         19426\n",
       "difficulty_average                                                   1.81642\n",
       "difficulty_count                                                        7294\n",
       "rating_average                                                       4.22529\n",
       "queued_projects_count                                                   7895\n",
       "rating_count                                                            6618\n",
       "pattern_type_names                                                       hat\n",
       "pattern_type_clothing                                                   True\n",
       "photos_url                 https://images4-f.ravelrycache.com/uploads/cas...\n",
       "pattern_needle_sizes       [{'id': 8, 'us': '8 ', 'metric': 5.0, 'us_stee...\n",
       "pattern_attributes         ['unisex', 'teen', 'adult', 'fitted', 'reversi...\n",
       "yardage_max                                                              NaN\n",
       "yardage                                                                   93\n",
       "generally_available                                2006/12/01 00:00:00 -0500\n",
       "gauge                                                                     20\n",
       "gauge_divisor                                                              4\n",
       "free                                                                    True\n",
       "downloadable                                                            True\n",
       "categories                           ['headband', 'headwear', 'accessories']\n",
       "yarn_weight_description                                         Aran (8 wpi)\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0e15891-9384-4411-b9eb-b2e68ba352cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hat', 'socks', 'gloves', 'bag', 'baby', 'blanket', 'cardigan',\n",
       "       'child', 'other', 'shawl', 'pullover', 'scarf', 'tee', 'toys',\n",
       "       'vest', 'camisole', 'home', 'dishcloth', 'pet', 'jacket', 'shrug',\n",
       "       'dress-suit', 'skirt', 'naughty', nan], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pattern_type_names.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ac720342-0785-4ba6-82dd-a068c5fd8db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['headband', 'mid-calf', 'beanie-toque', 'cardigan', 'babyblanket',\n",
       "       'fingerless', 'slippers', 'shawl-wrap', 'pullover', 'scarf',\n",
       "       'poncho', 'tee', 'onesies', 'ankle-sock', 'tube', 'other-socks',\n",
       "       'beret-tam', 'animal', 'coat', 'vest', 'sleeveless-top', 'mittens',\n",
       "       'earwarmers', 'cowl', 'market', 'convertible', 'balaclava',\n",
       "       'dress', 'doll', 'bib', 'earflap', 'other-blanket',\n",
       "       'christmasstocking', 'gloves', 'bedding', 'booties', 'bonnet',\n",
       "       'pet-clothing', 'afghanblock', 'throw', 'costume', 'towel',\n",
       "       'stocking', 'hangingornament', 'fashion-doll', 'scrubber', 'socks',\n",
       "       'washcloth', 'other-hands', 'other-neck-torso', 'pixie', 'shorts',\n",
       "       'hairaccessories', 'shrug', 'containers', 'drawstring', 'pillow',\n",
       "       'other-decorative', 'brimmed', 'legwarmers', 'other-cozy',\n",
       "       'other-accessories', 'tote', 'other-hat', 'knee-highs',\n",
       "       'other-dollclothes', 'potholder', 'leggings', 'toeless', 'cup-mug',\n",
       "       'electronics', 'bra', 'cape', 'soakers', 'pants', 'other-top',\n",
       "       'bedspread', 'other-headwear', 'coffee-teapot', 'food', 'skirt',\n",
       "       'other-bag', 'game', 'wallhanging', 'cuffs', 'purse', 'plant',\n",
       "       'bracelet', 'rug', 'cloche', 'coaster', 'bookmark', 'other-craft',\n",
       "       'other-softies', 'sweater', 'sleepwear', 'sportsequipment',\n",
       "       'thigh-high', 'boot-toppers', 'bookcover', 'wreath', 'other-home',\n",
       "       'hotwaterbottle', 'ball', 'other-cleaning', 'child-doll',\n",
       "       'stitchpattern', 'needleholder', 'collar', 'necktie', 'kerchief',\n",
       "       'other-sweater', 'baby-doll', 'edging', 'tutorial', 'blanket',\n",
       "       'yarmulke', 'headwrap', 'bathmitt', 'billed', 'tablerunner',\n",
       "       'tissueboxcover', 'wristlet', 'eyemask', 'accessory', 'doily',\n",
       "       'placemat', 'ornamentalflower', 'muff', 'other-feet-legs',\n",
       "       'brooch', 'medical', 'maturecontent', 'sachet', 'neck-torso',\n",
       "       'underwear', 'curtain', 'puppet', 'other-clothing', 'snood',\n",
       "       'toys', 'swimwear', 'maturecontenttoys', 'robe', 'clutch',\n",
       "       'foodcozy', 'lipbalm', 'vehicle', 'messenger', 'backpack', 'chart',\n",
       "       'pincushion', 'belt', 'spats', 'automobile', 'applique',\n",
       "       'other-toysandhobbies', 'mobile', 'other-intimateapparel',\n",
       "       'necklace', 'earrings', 'pictureframe', 'strapless-top',\n",
       "       'other-jewelry', 'intimateapparel', 'decorative', 'accessories',\n",
       "       'laptop', 'insertion', 'other-tablesetting', 'lampshade', 'blocks',\n",
       "       'glassescase', 'bathroom', 'tablecloth', 'money', 'home', 'ring',\n",
       "       'duffle', 'tapemeasurecover', 'other-pet', 'softies', 'clothing',\n",
       "       'napkin', 'crochethookholder', 'pasties', 'dollclothes',\n",
       "       'hangercover', 'headwear'], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.categories.unique() #193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "87d82f1d-4d07-40e6-b771-629463cfca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fabric_density_ratio(df):\n",
    "    df['fabric_density'] = df['yarn_weight_code']/df['pattern_needle_sizes']\n",
    "    return(df)\n",
    "#     ratio of need to needle size and yarn_weight\n",
    "df =create_fabric_density_ratio(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a0413614-2e88-4f99-8555-ce5797d74b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>188099</th>\n",
       "      <th>188110</th>\n",
       "      <th>188114</th>\n",
       "      <th>188117</th>\n",
       "      <th>188127</th>\n",
       "      <th>188148</th>\n",
       "      <th>188152</th>\n",
       "      <th>188153</th>\n",
       "      <th>188154</th>\n",
       "      <th>188156</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>favorites_count</th>\n",
       "      <td>29838</td>\n",
       "      <td>17795</td>\n",
       "      <td>3483</td>\n",
       "      <td>22539</td>\n",
       "      <td>1190</td>\n",
       "      <td>36858</td>\n",
       "      <td>29318</td>\n",
       "      <td>19644</td>\n",
       "      <td>47871</td>\n",
       "      <td>11364</td>\n",
       "      <td>...</td>\n",
       "      <td>709</td>\n",
       "      <td>576</td>\n",
       "      <td>88</td>\n",
       "      <td>224</td>\n",
       "      <td>598</td>\n",
       "      <td>151</td>\n",
       "      <td>103</td>\n",
       "      <td>353</td>\n",
       "      <td>647</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projects_count</th>\n",
       "      <td>19426</td>\n",
       "      <td>10987</td>\n",
       "      <td>6019</td>\n",
       "      <td>7325</td>\n",
       "      <td>2469</td>\n",
       "      <td>9212</td>\n",
       "      <td>5281</td>\n",
       "      <td>6391</td>\n",
       "      <td>11192</td>\n",
       "      <td>2559</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difficulty_average</th>\n",
       "      <td>1.81642</td>\n",
       "      <td>2.43558</td>\n",
       "      <td>2.85125</td>\n",
       "      <td>1.86568</td>\n",
       "      <td>2.85333</td>\n",
       "      <td>1.85447</td>\n",
       "      <td>2.26698</td>\n",
       "      <td>1.61973</td>\n",
       "      <td>2.48483</td>\n",
       "      <td>1.45052</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>2.42857</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.57143</td>\n",
       "      <td>1.66667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.33333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difficulty_count</th>\n",
       "      <td>7294</td>\n",
       "      <td>2670</td>\n",
       "      <td>921</td>\n",
       "      <td>2442</td>\n",
       "      <td>300</td>\n",
       "      <td>3209</td>\n",
       "      <td>1678</td>\n",
       "      <td>1825</td>\n",
       "      <td>3560</td>\n",
       "      <td>677</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_average</th>\n",
       "      <td>4.22529</td>\n",
       "      <td>4.45524</td>\n",
       "      <td>4.4933</td>\n",
       "      <td>4.26759</td>\n",
       "      <td>4.22378</td>\n",
       "      <td>4.47137</td>\n",
       "      <td>4.42963</td>\n",
       "      <td>4.39892</td>\n",
       "      <td>4.44425</td>\n",
       "      <td>4.48071</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.71429</td>\n",
       "      <td>4.72727</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.66667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queued_projects_count</th>\n",
       "      <td>7895</td>\n",
       "      <td>3519</td>\n",
       "      <td>463</td>\n",
       "      <td>4534</td>\n",
       "      <td>219</td>\n",
       "      <td>7641</td>\n",
       "      <td>4458</td>\n",
       "      <td>3378</td>\n",
       "      <td>8203</td>\n",
       "      <td>1331</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>91</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_count</th>\n",
       "      <td>6618</td>\n",
       "      <td>2480</td>\n",
       "      <td>896</td>\n",
       "      <td>2246</td>\n",
       "      <td>286</td>\n",
       "      <td>2951</td>\n",
       "      <td>1620</td>\n",
       "      <td>1662</td>\n",
       "      <td>3381</td>\n",
       "      <td>622</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pattern_type_names</th>\n",
       "      <td>hat</td>\n",
       "      <td>socks</td>\n",
       "      <td>socks</td>\n",
       "      <td>hat</td>\n",
       "      <td>socks</td>\n",
       "      <td>hat</td>\n",
       "      <td>baby</td>\n",
       "      <td>hat</td>\n",
       "      <td>baby</td>\n",
       "      <td>blanket</td>\n",
       "      <td>...</td>\n",
       "      <td>hat</td>\n",
       "      <td>shawl</td>\n",
       "      <td>baby</td>\n",
       "      <td>hat</td>\n",
       "      <td>gloves</td>\n",
       "      <td>dishcloth</td>\n",
       "      <td>shawl</td>\n",
       "      <td>scarf</td>\n",
       "      <td>scarf</td>\n",
       "      <td>shawl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pattern_type_clothing</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pattern_needle_sizes</th>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downloadable</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <td>headband</td>\n",
       "      <td>mid-calf</td>\n",
       "      <td>mid-calf</td>\n",
       "      <td>beanie-toque</td>\n",
       "      <td>mid-calf</td>\n",
       "      <td>beanie-toque</td>\n",
       "      <td>cardigan</td>\n",
       "      <td>beanie-toque</td>\n",
       "      <td>cardigan</td>\n",
       "      <td>babyblanket</td>\n",
       "      <td>...</td>\n",
       "      <td>beanie-toque</td>\n",
       "      <td>cowl</td>\n",
       "      <td>beanie-toque</td>\n",
       "      <td>beanie-toque</td>\n",
       "      <td>gloves</td>\n",
       "      <td>washcloth</td>\n",
       "      <td>shawl-wrap</td>\n",
       "      <td>scarf</td>\n",
       "      <td>scarf</td>\n",
       "      <td>shawl-wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yarn_weight_code</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauge_per_inch</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_avail</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_avail</th>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>...</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yardage_avg</th>\n",
       "      <td>93</td>\n",
       "      <td>370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234</td>\n",
       "      <td>460</td>\n",
       "      <td>140</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>828</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>492</td>\n",
       "      <td>162</td>\n",
       "      <td>344</td>\n",
       "      <td>420</td>\n",
       "      <td>120</td>\n",
       "      <td>960</td>\n",
       "      <td>1300</td>\n",
       "      <td>2600</td>\n",
       "      <td>3052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 132843 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2             3         4       \\\n",
       "favorites_count           29838     17795      3483         22539      1190   \n",
       "projects_count            19426     10987      6019          7325      2469   \n",
       "difficulty_average      1.81642   2.43558   2.85125       1.86568   2.85333   \n",
       "difficulty_count           7294      2670       921          2442       300   \n",
       "rating_average          4.22529   4.45524    4.4933       4.26759   4.22378   \n",
       "queued_projects_count      7895      3519       463          4534       219   \n",
       "rating_count               6618      2480       896          2246       286   \n",
       "pattern_type_names          hat     socks     socks           hat     socks   \n",
       "pattern_type_clothing      True      True      True          True      True   \n",
       "pattern_needle_sizes          5       2.5       NaN           3.5       2.5   \n",
       "free                       True      True     False          True     False   \n",
       "downloadable               True      True      True          True     False   \n",
       "categories             headband  mid-calf  mid-calf  beanie-toque  mid-calf   \n",
       "yarn_weight_code              8         2         3             5         2   \n",
       "gauge_per_inch                5         8       NaN           5.5       7.5   \n",
       "month_avail                  12         4         5             3        10   \n",
       "year_avail                 2006      2006      2007          2006      2007   \n",
       "yardage_avg                  93       370       NaN           234       460   \n",
       "\n",
       "                             5         8             9         10      \\\n",
       "favorites_count               36858     29318         19644     47871   \n",
       "projects_count                 9212      5281          6391     11192   \n",
       "difficulty_average          1.85447   2.26698       1.61973   2.48483   \n",
       "difficulty_count               3209      1678          1825      3560   \n",
       "rating_average              4.47137   4.42963       4.39892   4.44425   \n",
       "queued_projects_count          7641      4458          3378      8203   \n",
       "rating_count                   2951      1620          1662      3381   \n",
       "pattern_type_names              hat      baby           hat      baby   \n",
       "pattern_type_clothing          True      True          True      True   \n",
       "pattern_needle_sizes            4.5       3.5             4         5   \n",
       "free                           True      True          True      True   \n",
       "downloadable                   True      True          True      True   \n",
       "categories             beanie-toque  cardigan  beanie-toque  cardigan   \n",
       "yarn_weight_code                  8         3             8         8   \n",
       "gauge_per_inch                    5       5.5             5      3.75   \n",
       "month_avail                       3        11             2         4   \n",
       "year_avail                     2008      2008          2009      2009   \n",
       "yardage_avg                     140       300           100       300   \n",
       "\n",
       "                            11      ...        188099 188110        188114  \\\n",
       "favorites_count              11364  ...           709    576            88   \n",
       "projects_count                2559  ...            13     11            15   \n",
       "difficulty_average         1.45052  ...          2.75      5       2.33333   \n",
       "difficulty_count               677  ...             4      3             3   \n",
       "rating_average             4.48071  ...             5      5             5   \n",
       "queued_projects_count         1331  ...            74     40             3   \n",
       "rating_count                   622  ...             4      3             3   \n",
       "pattern_type_names         blanket  ...           hat  shawl          baby   \n",
       "pattern_type_clothing        False  ...          True   True          True   \n",
       "pattern_needle_sizes           4.5  ...           4.5   3.75          3.75   \n",
       "free                          True  ...         False  False         False   \n",
       "downloadable                  True  ...          True   True          True   \n",
       "categories             babyblanket  ...  beanie-toque   cowl  beanie-toque   \n",
       "yarn_weight_code                 8  ...             6      2             3   \n",
       "gauge_per_inch                   4  ...             5    5.5           5.5   \n",
       "month_avail                      5  ...             9     10            11   \n",
       "year_avail                    2009  ...          2019   2019          2019   \n",
       "yardage_avg                    828  ...           208    492           162   \n",
       "\n",
       "                             188117   188127     188148      188152 188153  \\\n",
       "favorites_count                 224      598        151         103    353   \n",
       "projects_count                   14       57         15          58     24   \n",
       "difficulty_average          2.42857      6.5    1.57143     1.66667    1.2   \n",
       "difficulty_count                  7       12          7           3      5   \n",
       "rating_average              4.71429  4.72727        4.5           5      5   \n",
       "queued_projects_count            23       76         23          17     49   \n",
       "rating_count                      7       11          8           3      6   \n",
       "pattern_type_names              hat   gloves  dishcloth       shawl  scarf   \n",
       "pattern_type_clothing          True     True      False        True   True   \n",
       "pattern_needle_sizes              3      1.5        4.5        3.75      5   \n",
       "free                          False    False       True       False   True   \n",
       "downloadable                   True     True       True       False   True   \n",
       "categories             beanie-toque   gloves  washcloth  shawl-wrap  scarf   \n",
       "yarn_weight_code                  2      1.5          6           2      6   \n",
       "gauge_per_inch                  6.5      NaN          5           4    5.5   \n",
       "month_avail                       9        3          4          12     12   \n",
       "year_avail                     2013     2014       2013        2020   2020   \n",
       "yardage_avg                     344      420        120         960   1300   \n",
       "\n",
       "                      188154      188156  \n",
       "favorites_count          647         357  \n",
       "projects_count            53          13  \n",
       "difficulty_average         3     1.33333  \n",
       "difficulty_count           4           3  \n",
       "rating_average          4.75     4.66667  \n",
       "queued_projects_count     91          44  \n",
       "rating_count               4           3  \n",
       "pattern_type_names     scarf       shawl  \n",
       "pattern_type_clothing   True        True  \n",
       "pattern_needle_sizes     4.5         3.5  \n",
       "free                    True       False  \n",
       "downloadable            True        True  \n",
       "categories             scarf  shawl-wrap  \n",
       "yarn_weight_code           3           2  \n",
       "gauge_per_inch          5.25         5.5  \n",
       "month_avail                1           9  \n",
       "year_avail              2021        2021  \n",
       "yardage_avg             2600        3052  \n",
       "\n",
       "[18 rows x 132843 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41fa7c1-30be-4f17-a42c-4f62c3a776e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_average_rating(df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e23114e-3ab8-46c1-bf31-2f5d94bde48f",
   "metadata": {},
   "source": [
    "### Visualize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb7f1023-80de-448b-aa03-50486587ef81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9e60145d-5254-4a5a-b977-69127ad265a3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9e60145d-5254-4a5a-b977-69127ad265a3\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('cosolidate_gauge',\n",
       "                 <__main__.DataframeFunctionTransformer object at 0x7ffbc0207e10>)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9d13585d-f0dd-4f8c-a983-e0fd0b2e5e12\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9d13585d-f0dd-4f8c-a983-e0fd0b2e5e12\">DataframeFunctionTransformer</label><div class=\"sk-toggleable__content\"><pre><__main__.DataframeFunctionTransformer object at 0x7ffbc0207e10></pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cosolidate_gauge',\n",
       "                 <__main__.DataframeFunctionTransformer object at 0x7ffbc0207e10>)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456697d9-dfd8-40b7-855d-967853ffe5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "process difficulty and rating average down to 3 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a612f1-ad24-4b94-b61e-7a0befa10c07",
   "metadata": {},
   "source": [
    "#### columns I'm unsure about:\n",
    "Downloadable - do I keep?\n",
    "Make sure yarn weight is filled - which one?? and related it back to yarn weight name\n",
    "** fix pattern needles size\n",
    "row gauge?? is this needed?? probably not, other gauge should be fine\n",
    "** need a function to impute missing values!! figure out what should be for each row\n",
    "** if lots on a particular row, drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a233928-18be-4337-89e3-5edbff89e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370952a5-7bd2-4ca4-becc-6408de7302fc",
   "metadata": {},
   "source": [
    "#### Get pattern page link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79a6c7-0c3d-4e4f-8f52-dbe8cb79c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = f'https://www.ravelry.com/patterns/library/{permalink}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
